# Web Data Scrapers

## Introduction
The ability to differentiate oneself through the use of data is more important in today's tough corporate environment. With the increasing number of people using the internet and spending more time on social media platforms, the volume of user-generated data has skyrocketed. Web scraping has evolved into a vital technique for analyzing this massive amount of information and converting it into a lucrative venture. This project aims to utilize web scraping to automatically collect structured data from websites' public resources, specifically targeting Reddit, Twitter, and Facebook as primary social media channels.

## Problem Statement
The major goal of this project is to learn about different web scraping tools and evaluate them based on key criteria such as speed, ease of use, compatibility with other programs, number of languages supported, and number of platforms. The project will use a variety of scraping techniques to gather data from the selected social media platforms and then evaluate the outcomes to determine which tools are the most effective. The collected data will include usernames, tweet content, replies, number of likes, number of retweets, post text, likes, shares, comments, and upvotes, depending on the specific website.

## Tools Used
This project utilizes four web scraping tools/packages:

- Scrapy
- Octoparse
- Selenium
- Reaper

## Dataset
Data has become a major differentiator in today's business world, and web scraping has become a valuable tool for analyzing this data. The project aims to collect data from Reddit, Twitter, and Facebook for potential future commercial or promotional use. The specific data formats used by each website include usernames, tweet content, replies, number of likes, number of retweets, post text, likes, shares, comments, and upvotes. The collected data will be transformed into CSV files for easy analysis.

## Evaluations (Metrics, Experiments, Findings)
The project will employ accessible tools like Selenium, Scrapy, and Reaper to crawl social media platforms for information. The project is divided into two stages - the validation phase and the analysis stage. The validation process includes retrieving information from all sites and cross-checking the information using multiple tools to ensure accuracy. The analysis phase involves assessing the tools based on factors such as the regularity of content retrieval, record extraction capacity, accuracy and consistency of collected data, and ease of use. Based on these assessments, the effectiveness of each web scraping tool will be determined.

## Conclusion
Based on the investigations into online scraping technology, the project has learned that data collection from the world wide web is now easier than ever thanks to the use of automated tools. The project aims to utilize web scraping techniques to collect structured data from social media platforms and evaluate the effectiveness of different web scraping tools based on various criteria.
